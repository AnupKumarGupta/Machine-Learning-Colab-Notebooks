{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FInal Predict Next Word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLPrbhrZ5ha3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import gensim\n",
        "import string\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9n45Rdz52Cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to the dataset\n",
        "path = \"/content/sherlock_book.txt\"\n",
        "\n",
        "# Data Cleaning and Preprocessing \n",
        "\n",
        "# Restriction on the maximum length of sentence in terms of number of words\n",
        "max_sentence_len = 40\n",
        "\n",
        "# Open data file and read the data as lines\n",
        "with open(path) as file_:\n",
        "  docs = file_.readlines()\n",
        "\n",
        "# Preprocessing the data\n",
        "# 1. Converting the words into lower cases\n",
        "# 2. Removing punctuation marks\n",
        "# 3. Spliting the sentence into two if the max length exceeds\n",
        "# 4. Remove the sentences which are empty or too short \n",
        "sentences = [[word for word in doc.lower().translate(str.maketrans('','',string.punctuation)).split()[:max_sentence_len]] for doc in docs]\n",
        "sentences = [item for item in sentences if len(item) > 2]\n",
        "print('Num of sentences:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdyFtEeS70-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the Word2Vec model\n",
        "word_model = gensim.models.Word2Vec(sentences, size=100, min_count=1, window=5, iter=100)\n",
        "pretrained_weights = word_model.wv.vectors\n",
        "vocab_size, emdedding_size = pretrained_weights.shape\n",
        "\n",
        "# Embeddings shape will be : word count X size of vector\n",
        "print('Result embedding shape:', pretrained_weights.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lubkEgR692Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving the model \n",
        "model_path = \"sherlock_model\"\n",
        "word_model.save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6TDN7Y5IPgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retriving 'topn' words similar to 'word'\n",
        "def get_most_similar(word,topn):\n",
        "  try:\n",
        "    print(word_model.most_similar(word,topn=topn))\n",
        "  except:\n",
        "    print(\"Word <\",word,\"> not in vocabulary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho_mEYCBI2Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to return index of 'word' in the word2vec model\n",
        "# Returns -1 if the 'word' is not present in the vocab \n",
        "def word2idx(word):\n",
        "  try:\n",
        "   index = word_model.wv.vocab[word].index\n",
        "  except:\n",
        "   index = -1\n",
        "  return index   \n",
        "\n",
        "# Method to return 'word' at a particular index in the word2vec model\n",
        "# Returns empty string if the index is out of bounds\n",
        "def idx2word(idx):\n",
        "  try:\n",
        "    word = word_model.wv.index2word[idx]\n",
        "  except:\n",
        "    word = \"\"  \n",
        "  return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzU65KYdI4Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing the input and coresspondings output for training the LSTMs\n",
        "train_x = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
        "train_y = np.zeros([len(sentences)], dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, word in enumerate(sentence[:-1]):\n",
        "    train_x[i, t] = word2idx(word)\n",
        "  train_y[i] = word2idx(sentence[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmLX-e-kI4S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LSTM model \n",
        "lstm_model = tf.keras.models.Sequential()\n",
        "lstm_model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[pretrained_weights]))\n",
        "lstm_model.add(tf.keras.layers.LSTM(units=emdedding_size))\n",
        "lstm_model.add(tf.keras.layers.Dense(units=vocab_size))\n",
        "lstm_model.add(tf.keras.layers.Activation('softmax'))\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu7Sj0xdJNE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to generate next samples using a temprature, \n",
        "# instead of vanila argmax\n",
        "def sample(preds, temperature=1.0):\n",
        "  if temperature <= 0:\n",
        "    return np.argmax(preds)\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwwDsQPjJSEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to generate next 'count' words if a 'text' is provided\n",
        "def generate_next(lstm_model, text, count=10):\n",
        "  word_idxs = [word2idx(word) for word in text.lower().split()]\n",
        "  for i in range(count):\n",
        "    prediction = lstm_model.predict(x=np.array(word_idxs))\n",
        "    idx = sample(prediction[-1], temperature=0.7)\n",
        "    word_idxs.append(idx)  \n",
        "  return ' '.join(idx2word(idx) for idx in word_idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6zip0i7JVwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a callback to save the LSTM model after every epoch\n",
        "filepath=\"weights-improvement-{epoch:02d}-.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath,verbose=1, save_best_only=False, save_weights_only=False, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXqXRLCpJX6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the LSTM model\n",
        "lstm_model.fit(train_x, train_y,\n",
        "          batch_size=128,\n",
        "          epochs=25,\n",
        "          callbacks =callbacks_list, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}